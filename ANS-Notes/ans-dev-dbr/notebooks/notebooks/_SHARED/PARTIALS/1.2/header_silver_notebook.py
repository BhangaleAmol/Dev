# Databricks notebook source
# INPUT PARAMETERS
append_only = get_json_param('config', 'append_only', "bool", False)
change_path = get_json_param('config', 'change_path', "bool", False)
database_name = get_json_param('config', 'database_name') 
delete_type = get_json_param('config', 'delete_type', "string", "soft_delete")
handle_delete = get_json_param('config', 'handle_delete', "bool", False)
incremental = get_json_param('config', 'incremental', "bool", False)
overwrite = get_json_param('config', 'overwrite', "bool", False)
partition_column = get_json_param('config', 'partition_column')
prune_days = get_json_param('config', 'prune_days', "int", 30)
run_datetime = dt.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
sampling = get_json_param('config', 'sampling', "bool", False) 
table_name = get_json_param('config', 'table_name')
target_container = get_json_param('config', 'target_container', 'string', 'datalake')
target_folder = get_json_param('config', 'target_folder')
target_storage = get_json_param('config', 'target_storage', 'string', 'edmans{env}data001')
temp_folder = get_json_param('config', 'temp_folder')
test_run = get_json_param('config', 'test_run', "bool", False)

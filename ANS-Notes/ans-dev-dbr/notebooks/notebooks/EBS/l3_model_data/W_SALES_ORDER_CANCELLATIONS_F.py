# Databricks notebook source
# MAGIC %run ../SHARED/bootstrap

# COMMAND ----------

# Get parameters
dbutils.widgets.text("source_folder", "","")
sourceFolder = getArgument("source_folder")
sourceFolder = '/datalake/EBS/raw_data/delta_data' if sourceFolder == '' else sourceFolder

dbutils.widgets.text("target_folder", "","")
targetFolder = getArgument("target_folder")
targetFolder = '/datalake/EBS/stage_data' if targetFolder == '' else targetFolder

dbutils.widgets.text("table_name", "","")
tableName = getArgument("table_name")
tableName = 'W_SALES_ORDER_LINE_F' if tableName == '' else tableName

# COMMAND ----------

# Create paths

sourceFolderUrl = DATALAKE_ENDPOINT  + sourceFolder + '/'
sourceFolderCsvUrl = DATALAKE_ENDPOINT + '/datalake/EBS/raw_data/domain_values/'
targetFileUrl = DATALAKE_ENDPOINT +  targetFolder + '/' + tableName + '.par'

print(sourceFolderUrl)
print(sourceFolderCsvUrl)
print(targetFileUrl)

# COMMAND ----------

W_SALES_ORDER_CANCELLATIONS_F = spark.sql("""
SELECT  
     CONCAT(INT(OE_ORDER_LINES_HISTORY.LINE_ID), '-', OE_ORDER_LINES_HISTORY.HIST_TYPE_CODE , '-' ,  DATE_FORMAT(OE_ORDER_LINES_HISTORY.HIST_CREATION_DATE, "yyyyMMdd"), '-', INT(OE_ORDER_LINES_HISTORY.REASON_ID) ) INTEGRATION_ID,
     DATE_FORMAT(OE_ORDER_LINES_HISTORY.HIST_CREATION_DATE,'yyyy-MM-dd HH:mm:ss.SSS') CREATED_ON_DT,
     DATE_FORMAT(OE_ORDER_LINES_HISTORY.HIST_CREATION_DATE,'yyyy-MM-dd HH:mm:ss.SSS') CHANGED_ON_DT,
     INT(OE_ORDER_LINES_HISTORY.HIST_CREATED_BY) CREATED_BY_ID,
     INT(OE_ORDER_LINES_HISTORY.HIST_CREATED_BY) CHANGED_BY_ID,
     DATE_FORMAT(CURRENT_TIMESTAMP,'yyyy-MM-dd HH:mm:ss.SSS') INSERT_DT,  
     DATE_FORMAT(CURRENT_TIMESTAMP,'yyyy-MM-dd HH:mm:ss.SSS') UPDATE_DT,
     'EBS' DATASOURCE_NUM_ID,
     DATE_FORMAT(CURRENT_TIMESTAMP(),'yyyyMMddHHmmssSSS') LOAD_BATCH_ID,
     ''  BATCH_SOURCE_NAME,
     'N' CANCELLED_FLG,
     'N' DELETE_FLG,
     REPLACE(STRING(INT(OE_ORDER_LINES_HISTORY.LINE_ID)), ",", "") LINE_ID,
     FND_LOOKUP_VALUES.MEANING CANCEL_REASON,
     OE_REASONS.REASON_CODE  REASON_CODE,
     OE_REASONS.COMMENTS  REASON_COMMENT,
     OE_ORDER_LINES_HISTORY.ORDERED_QUANTITY ORDERED_QTY,
     OE_ORDER_LINES_HISTORY.CANCELLED_QUANTITY CANCELLED_QTY,
     OE_ORDER_LINES_HISTORY.LATEST_CANCELLED_QUANTITY LATEST_CANCELLED_QTY,
     OE_ORDER_LINES_HISTORY.HIST_TYPE_CODE,
     OE_ORDER_HEADERS_ALL.TRANSACTIONAL_CURR_CODE DOC_CURR_CODE,
     GL_SETS_OF_BOOKS.CURRENCY_CODE LOC_CURR_CODE,
     CONCAT(COALESCE(OE_ORDER_HEADERS_ALL.TRANSACTIONAL_CURR_CODE,''),'-',COALESCE(GL_SETS_OF_BOOKS.CURRENCY_CODE,''),'-Corporate-',COALESCE(DATE_FORMAT(OE_ORDER_HEADERS_ALL.ORDERED_DATE, "yyyyMMdd"),'')) EXCHG_INTEGRATION_ID,
     OE_ORDER_LINES_HISTORY.HEADER_ID SALES_ORDER_HD_ID,
     OE_ORDER_LINES_HISTORY.LINE_NUMBER SALES_ORDER_ITEM,
     OE_ORDER_LINES_HISTORY.SHIPMENT_NUMBER SALES_ORDER_ITEM_DETAIL_NUM,
     OE_ORDER_HEADERS_ALL.ORDER_NUMBER SALES_ORDER_NUM,
     OE_ORDER_LINES_HISTORY.ORDER_QUANTITY_UOM SALES_UOM_CODE,
     OE_ORDER_LINES_HISTORY.FLOW_STATUS_CODE SOURCE_ORDER_STATUS,
     OE_ORDER_LINES_HISTORY.UNIT_LIST_PRICE * OE_ORDER_LINES_HISTORY.LATEST_CANCELLED_QUANTITY  CANCELLED_LIST_AMT,
     OE_ORDER_LINES_HISTORY.UNIT_SELLING_PRICE * OE_ORDER_LINES_HISTORY.LATEST_CANCELLED_QUANTITY CANCELLED_AMT,
     DATE_FORMAT(OE_ORDER_LINES_HISTORY.HIST_CREATION_DATE, "yyyyMMdd") CANCELLED_ON_DT_ID,
     REPLACE(STRING(INT(OE_ORDER_LINES_HISTORY.SHIP_FROM_ORG_ID)), ",", "") INVENTORY_ORG_ID,
     REPLACE(STRING(INT(OE_ORDER_LINES_HISTORY.ORG_ID)), ",", "") OPERATING_UNIT_ORG_ID,
     REPLACE(STRING(INT(OE_ORDER_LINES_HISTORY.INVENTORY_ITEM_ID)), ",", "") PRODUCT_ID
FROM
    OE_ORDER_LINES_HISTORY
    INNER JOIN OE_ORDER_HEADERS_ALL
      ON OE_ORDER_LINES_HISTORY.HEADER_ID = OE_ORDER_HEADERS_ALL.HEADER_ID
    INNER JOIN OE_REASONS
      ON OE_ORDER_LINES_HISTORY.REASON_ID = OE_REASONS.REASON_ID
    INNER JOIN FND_LOOKUP_VALUES
      ON OE_REASONS.REASON_CODE = FND_LOOKUP_VALUES.LOOKUP_CODE
    INNER JOIN HR_OPERATING_UNITS  
      ON OE_ORDER_LINES_HISTORY.ORG_ID = HR_OPERATING_UNITS.ORGANIZATION_ID
    INNER JOIN GL_SETS_OF_BOOKS  
      ON HR_OPERATING_UNITS.SET_OF_BOOKS_ID = GL_SETS_OF_BOOKS.SET_OF_BOOKS_ID
WHERE
    FND_LOOKUP_VALUES.LOOKUP_TYPE = 'CANCEL_CODE'
    AND FND_LOOKUP_VALUES.LANGUAGE = 'US'
""")

W_SALES_ORDER_CANCELLATIONS_F.createOrReplaceTempView("W_SALES_ORDER_CANCELLATIONS_F")
W_SALES_ORDER_CANCELLATIONS_F.cache()
W_SALES_ORDER_CANCELLATIONS_F.count()

# COMMAND ----------

count = W_SALES_ORDER_CANCELLATIONS_F.select("INTEGRATION_ID").count()
countDistinct = W_SALES_ORDER_CANCELLATIONS_F.select("INTEGRATION_ID").distinct().count()

print(count)
print(countDistinct)

# Integration_id is not supposed to be unique

#if(count != countDistinct):
#  message = 'Mismatch in count of total records ({0}) and distinct count of primary keys ({1}) in {2} '.format(count, countDistinct, tableName)
#  raise Exception(message)

# COMMAND ----------

W_SALES_ORDER_CANCELLATIONS_F.coalesce(10).write.format("parquet").mode("overwrite").save(targetFileUrl)

# COMMAND ----------

W_SALES_ORDER_CANCELLATIONS_F.unpersist()

# COMMAND ----------


